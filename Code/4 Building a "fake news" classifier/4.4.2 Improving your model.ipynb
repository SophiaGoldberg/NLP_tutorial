{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.2 Improving your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# # Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "df=pd.DataFrame.from_csv('fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   title  \\\n",
      "8476                        You Can Smell Hillary’s Fear   \n",
      "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "3608         Kerry to go to Paris in gesture of sympathy   \n",
      "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "875     The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                    text label  \n",
      "8476   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "3608   U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "875    It's primary day in New York and front-runners...  REAL  \n"
     ]
    }
   ],
   "source": [
    "# Print the head of df\n",
    "print(df.head())\n",
    "\n",
    "# Create a series to store the labels: y\n",
    "y = df.label\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                             df['text'], y, \n",
    "                                             test_size=0.33, \n",
    "                                             random_state=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophia/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n",
      "  (1, 42470)\t0.07711040274149526\n",
      "  (1, 12105)\t0.15008066461476866\n",
      "  (1, 54177)\t0.13782629144711137\n",
      "  (1, 50628)\t0.061296988343109586\n",
      "  (1, 15924)\t0.3479045460649079\n",
      "  (1, 44520)\t0.4973826512693341\n",
      "  (1, 51896)\t0.11596517664605868\n",
      "  (1, 35783)\t0.30902690818827977\n",
      "  (1, 35256)\t0.12628385718450857\n",
      "  (1, 21881)\t0.21271688045815978\n",
      "  (1, 42534)\t0.06081715886809217\n",
      "  (1, 8399)\t0.08729542880625335\n",
      "  (1, 29531)\t0.1454406205718245\n",
      "  (1, 15927)\t0.4973826512693341\n",
      "  (1, 25686)\t0.13550453594288983\n",
      "  (1, 49203)\t0.1672740861784377\n",
      "  (1, 16814)\t0.10404977746548139\n",
      "  (1, 36087)\t0.12648679854389897\n",
      "  (1, 21568)\t0.1007920919566398\n",
      "  (1, 25684)\t0.1030420922189754\n",
      "  (1, 38823)\t0.06048803110658644\n",
      "  (1, 47506)\t0.14539060877460044\n",
      "  (1, 36831)\t0.10772488937433067\n",
      "  (2, 16972)\t0.1606296088662543\n",
      "  (2, 762)\t0.48803966069171073\n",
      "  :\t:\n",
      "  (4, 19325)\t0.05452053080897492\n",
      "  (4, 7259)\t0.06755319386644243\n",
      "  (4, 51456)\t0.06475353785981061\n",
      "  (4, 7426)\t0.06511222583761835\n",
      "  (4, 39829)\t0.05465988305311523\n",
      "  (4, 9486)\t0.0498567667112753\n",
      "  (4, 27568)\t0.028302541956335657\n",
      "  (4, 48702)\t0.1743065129793454\n",
      "  (4, 41541)\t0.03347420115927609\n",
      "  (4, 20268)\t0.040257433434577744\n",
      "  (4, 44567)\t0.04521244574721562\n",
      "  (4, 7184)\t0.04119900385804159\n",
      "  (4, 15056)\t0.06406962747278261\n",
      "  (4, 23980)\t0.040601095306683384\n",
      "  (4, 36845)\t0.03921825297423197\n",
      "  (4, 37249)\t0.04750657931325537\n",
      "  (4, 12692)\t0.0406789533096042\n",
      "  (4, 43655)\t0.07010870747834863\n",
      "  (4, 4093)\t0.059095267180806606\n",
      "  (4, 26966)\t0.031877860469596585\n",
      "  (4, 9120)\t0.02872653761009892\n",
      "  (4, 5676)\t0.059095267180806606\n",
      "  (4, 22019)\t0.07963078672826533\n",
      "  (4, 43462)\t0.12234830953369169\n",
      "  (4, 23468)\t0.03469208821573642\n"
     ]
    }
   ],
   "source": [
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
    "\n",
    "# Transform the test data: tfidf_test \n",
    "# DO NOT FIT TEST DATA because test data may include NEW WORDS\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.6150167384026781\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.8976566236250598\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.8938307030129125\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.8900047824007652\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.8857006217120995\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.8842659014825442\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.874701099952176\n",
      "\n",
      "Alpha:  0.7000000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophia/anaconda3/lib/python3.6/site-packages/sklearn/naive_bayes.py:699: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8703969392635102\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.8660927785748446\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.8589191774270684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(0,1,0.1)\n",
    "\n",
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "# Iterate over the alphas and print the corresponding score\n",
    "accuracy_dict={}\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    accuracy=train_and_predict(alpha)\n",
    "    print('Score: ', accuracy)\n",
    "    print()\n",
    "    accuracy_dict[str(alpha)]=accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.0': 0.6150167384026781,\n",
       " '0.1': 0.8976566236250598,\n",
       " '0.2': 0.8938307030129125,\n",
       " '0.30000000000000004': 0.8900047824007652,\n",
       " '0.4': 0.8857006217120995,\n",
       " '0.5': 0.8842659014825442,\n",
       " '0.6000000000000001': 0.874701099952176,\n",
       " '0.7000000000000001': 0.8703969392635102,\n",
       " '0.8': 0.8660927785748446,\n",
       " '0.9': 0.8589191774270684}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
